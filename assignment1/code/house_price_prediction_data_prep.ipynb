{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import json \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import regex as re\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current code folder\n",
    "current_path = os.getcwd()\n",
    "\n",
    "# Get the assignment1 folder\n",
    "if \"code\" in current_path:\n",
    "    assignment_dir = os.path.dirname(current_path)\n",
    "else:\n",
    "    assignment_dir = current_path\n",
    "\n",
    "# Location folders\n",
    "data_in = os.path.join(assignment_dir, \"data\", \"raw/\")\n",
    "data_out = os.path.join(assignment_dir, \"data\", \"clean/\")\n",
    "output = os.path.join(assignment_dir, \"output/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Function\n",
    "\n",
    "The following function contains all data cleaning steps. It will be applied to each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Clean an Airbnb dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        dataset: str - e.g. 'madrid_25q1', 'madrid_25q2', 'valencia_25q1'\n",
    "    \"\"\"\n",
    "    \n",
    "    input_file = f\"listings_{dataset}.csv\"\n",
    "    output_file = f\"airbnb_{dataset}_clean.csv\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"CLEANING: {dataset}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # --------------------------------------------------------\n",
    "    # READ DATA\n",
    "    # --------------------------------------------------------\n",
    "    df = pd.read_csv(data_in + input_file)\n",
    "    print(f\"\\nLoaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    \n",
    "    # --------------------------------------------------------\n",
    "    # CLEAN PRICE (TARGET)\n",
    "    # --------------------------------------------------------\n",
    "    df['price'] = df['price'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "    df = df[(df['price'].notna()) & (df['price'] > 0) & (df['price'] < 1000)]\n",
    "    print(f\"After price filter: {df.shape[0]} rows\")\n",
    "    \n",
    "    df[\"ln_price\"] = np.log(df.price)\n",
    "    \n",
    "    # --------------------------------------------------------\n",
    "    # PROPERTY TYPE - simplify to Apartment/House/Other\n",
    "    # --------------------------------------------------------\n",
    "    def simplify_property(pt):\n",
    "        if pd.isna(pt):\n",
    "            return 'Other'\n",
    "        pt = pt.lower()\n",
    "        if any(x in pt for x in ['apartment', 'rental unit', 'condo', 'loft', 'serviced']):\n",
    "            return 'Apartment'\n",
    "        if any(x in pt for x in ['house', 'home', 'townhouse', 'villa', 'cottage', 'bungalow', 'cabin']):\n",
    "            return 'House'\n",
    "        return 'Other'\n",
    "    \n",
    "    df['f_property_type'] = df['property_type'].apply(simplify_property).astype('category')\n",
    "    \n",
    "    # Exclude hotels and hostels (for better comparability, only dropping a few observations)\n",
    "    df = df[~df['property_type'].str.lower().str.contains('hotel|hostel', na=False)]\n",
    "    print(f\"After excluding hotels/hostels: {df.shape[0]} rows\")\n",
    "    \n",
    "    # --------------------------------------------------------\n",
    "    # FACTOR VARIABLES\n",
    "    # --------------------------------------------------------\n",
    "    df = df[~df['room_type'].str.lower().str.contains('hotel|hostel', na=False)]\n",
    "    df['f_room_type'] = df['room_type'].astype('category')\n",
    "    \n",
    "    # Keep only neighbourhoods with at least 30 observations (important for cross validation, rare neighbourhoods are problematic)\n",
    "    # Later on I decided to exlude neigbourhood variable: external validation using Valencia does not work\n",
    "    neighbourhood_counts = df['neighbourhood_cleansed'].value_counts()\n",
    "    keep_neighbourhoods = neighbourhood_counts[neighbourhood_counts >= 30].index\n",
    "    df = df[df['neighbourhood_cleansed'].isin(keep_neighbourhoods)]\n",
    "    df['f_neighbourhood_cleansed'] = df['neighbourhood_cleansed'].astype('category')\n",
    "    \n",
    "    # --------------------------------------------------------\n",
    "    # NUMERICAL VARIABLES\n",
    "    # --------------------------------------------------------\n",
    "    df['n_accommodates'] = df['accommodates'].astype(float)\n",
    "    df['n_bedrooms'] = df['bedrooms'].astype(float)\n",
    "    df['n_beds'] = df['beds'].astype(float)\n",
    "    df['n_bathrooms'] = df['bathrooms'].astype(float)\n",
    "    \n",
    "    # Fill missing bathrooms from bathrooms_text\n",
    "    mask = df['n_bathrooms'].isna() & df['bathrooms_text'].notna()\n",
    "    df.loc[mask, 'n_bathrooms'] = df.loc[mask, 'bathrooms_text'].str.extract(r'(\\d+\\.?\\d*)')[0].astype(float)\n",
    "    \n",
    "    # Other numerical variables\n",
    "    df['n_number_of_reviews'] = df['number_of_reviews'].astype(float)\n",
    "    df['n_reviews_per_month'] = df['reviews_per_month'].astype(float)\n",
    "    df['n_review_scores_rating'] = df['review_scores_rating'].astype(float)\n",
    "    df['n_minimum_nights'] = df['minimum_nights'].astype(float)\n",
    "    df['n_availability_365'] = df['availability_365'].astype(float)\n",
    "    df['n_host_listings_count'] = df['host_listings_count'].astype(float)\n",
    "    \n",
    "    # Host response rate\n",
    "    df['p_host_response_rate'] = df['host_response_rate'].str.replace('%', '').astype(float)\n",
    "    \n",
    "    # --------------------------------------------------------\n",
    "    # DUMMY VARIABLES (binary)\n",
    "    # --------------------------------------------------------\n",
    "    df['d_host_is_superhost'] = (df['host_is_superhost'] == 't').astype(int)\n",
    "    df['d_instant_bookable'] = (df['instant_bookable'] == 't').astype(int)\n",
    "    df['d_host_identity_verified'] = (df['host_identity_verified'] == 't').astype(int)\n",
    "    \n",
    "    # --------------------------------------------------------\n",
    "    # DAYS SINCE FIRST REVIEW\n",
    "    # --------------------------------------------------------\n",
    "    df['n_days_since'] = (pd.to_datetime(df['last_scraped']) - pd.to_datetime(df['first_review'])).dt.days\n",
    "    \n",
    "    # --------------------------------------------------------\n",
    "    # AMENITIES EXTRACTION\n",
    "    # --------------------------------------------------------\n",
    "    def parse_amenities(x):\n",
    "        if pd.isna(x): return []\n",
    "        try: return json.loads(x)\n",
    "        except: return re.findall(r'\"([^\"]*)\"', x)\n",
    "    \n",
    "    df['amenities_list'] = df['amenities'].apply(parse_amenities)\n",
    "    \n",
    "    amenities_to_extract = [\n",
    "        'Wifi', 'Air conditioning', 'Heating', 'Kitchen', 'Washer', 'Dryer',\n",
    "        'TV', 'Hair dryer', 'Iron', 'Elevator', 'Free parking', 'Pool', 'Dishes and silverware',\n",
    "        'Hot tub', 'Gym', 'Self check-in', 'Smoking allowed', 'Pets allowed', 'Hot water',\n",
    "        'Coffee maker', 'Dishwasher', 'Microwave', 'Refrigerator', 'Balcony',\n",
    "        'Fire extinguisher', 'Smoke alarm', 'Carbon monoxide alarm', \n",
    "        'Dedicated workspace', 'Essentials', 'Hangers', 'Bed linens'\n",
    "    ]\n",
    "    \n",
    "    for amenity in amenities_to_extract:\n",
    "        col_name = 'd_' + re.sub(r'[^a-z0-9]', '', amenity.lower())\n",
    "        df[col_name] = df['amenities_list'].apply(\n",
    "            lambda x: int(any(amenity.lower() in a.lower() for a in x))\n",
    "        )\n",
    "    \n",
    "    df['n_amenities_count'] = df['amenities_list'].apply(len)\n",
    "    \n",
    "    # --------------------------------------------------------\n",
    "    # DERIVED FEATURES\n",
    "    # --------------------------------------------------------\n",
    "    df['n_accommodates2'] = df['n_accommodates'] ** 2\n",
    "    df['ln_accommodates'] = np.log(df['n_accommodates'] + 1)\n",
    "    df['ln_accommodates2'] = df['ln_accommodates'] ** 2\n",
    "    df['ln_beds'] = np.log(df['n_beds'].fillna(1) + 1)\n",
    "    df['ln_number_of_reviews'] = np.log(df['n_number_of_reviews'] + 1)\n",
    "    \n",
    "    # --------------------------------------------------------\n",
    "    # CATEGORICAL BINS\n",
    "    # --------------------------------------------------------\n",
    "    df['f_bathroom'] = pd.cut(df['n_bathrooms'].fillna(1), bins=[-0.1, 0.9, 1.9, 100], labels=[0, 1, 2])\n",
    "    df['f_number_of_reviews'] = pd.cut(df['n_number_of_reviews'], bins=[-0.1, 0.9, 10, 50, 10000], labels=[0, 1, 2, 3])\n",
    "    df['f_minimum_nights'] = pd.cut(df['n_minimum_nights'], bins=[0, 1, 2, 7, 10000], labels=[1, 2, 3, 4])\n",
    "    \n",
    "    # --------------------------------------------------------\n",
    "    # HANDLE MISSING VALUES\n",
    "    # --------------------------------------------------------\n",
    "    # Impute missign with median\n",
    "    for col in ['n_bathrooms', 'n_beds', 'n_bedrooms']:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "    for col in ['n_days_since', 'n_review_scores_rating', 'n_reviews_per_month', 'p_host_response_rate']:\n",
    "        flag_name = 'flag_' + col.replace('n_', '').replace('p_', '')\n",
    "        df[flag_name] = df[col].isna().astype(int)\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "    # Recalculate log features after imputation\n",
    "    df['ln_beds'] = np.log(df['n_beds'] + 1)\n",
    "    df['ln_days_since'] = np.log(df['n_days_since'] + 1)\n",
    "    df['ln_days_since2'] = df['ln_days_since'] ** 2\n",
    "    df['ln_days_since3'] = df['ln_days_since'] ** 3\n",
    "    df['ln_review_scores_rating'] = np.log(df['n_review_scores_rating'] + 0.01)\n",
    "    \n",
    "    # Replace infinities with nan\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    df[numeric_cols] = df[numeric_cols].replace([np.inf, -np.inf], np.nan)\n",
    "    df[numeric_cols] = df[numeric_cols].fillna(0)\n",
    "    \n",
    "    # Fill categorical NAs with mode (most common category)\n",
    "    categorical_cols = df.select_dtypes(include=['category']).columns\n",
    "    for col in categorical_cols:\n",
    "        if df[col].isna().any():\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    \n",
    "    # --------------------------------------------------------\n",
    "    # SELECT FINAL COLUMNS\n",
    "    # --------------------------------------------------------\n",
    "    keep_cols = ['id', 'price', 'latitude', 'longitude']\n",
    "    keep_cols += [c for c in df.columns if c.startswith(('f_', 'n_', 'd_', 'ln_', 'p_', 'flag_'))]\n",
    "    keep_cols = list(dict.fromkeys(keep_cols))\n",
    "    \n",
    "    data = df[keep_cols].copy()\n",
    "    \n",
    "    # --------------------------------------------------------\n",
    "    # SAVE\n",
    "    # --------------------------------------------------------\n",
    "    data.to_csv(data_out + output_file, index=False)\n",
    "    \n",
    "    print(f\"\\nFinal shape: {data.shape}\")\n",
    "    print(f\"Saved to: {data_out}{output_file}\")\n",
    "    print(f\"Price: mean={data['price'].mean():.0f}, median={data['price'].median():.0f}\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Steps\n",
    "\n",
    "### 1. Price (Target Variable)\n",
    "- Remove dollar signs and commas\n",
    "- Filter to valid prices: >0 and <1000\n",
    "- Create log transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Property Type\n",
    "- Simplify to three categories: Apartment, House, Other\n",
    "- Exclude hotels and hostels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Factor Variables\n",
    "- Room type: converted to category\n",
    "- Neighbourhood: keep only those with 30+ observations (for cross-validation stability). Eventually dropped from final set for external validity reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Numerical Variables\n",
    "- Accommodates, bedrooms, beds, bathrooms\n",
    "- Reviews: count, rating, per month\n",
    "- Host response rate (converted from percentage string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Dummy Variables\n",
    "- Superhost status\n",
    "- Instant bookable\n",
    "- Host identity verified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Amenities\n",
    "- Parse JSON/string amenities list\n",
    "- Extract 31 key amenities as binary dummies\n",
    "- Count total amenities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Derived Features\n",
    "- Polynomial terms: accommodates², ln(accommodates)\n",
    "- Log transformations for skewed variables\n",
    "- Categorical bins for bathrooms, reviews, minimum nights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Missing Values\n",
    "- Numerical: impute with median\n",
    "- Categorical: impute with mode\n",
    "- Create flags for imputed values (days_since, review_scores, etc.)\n",
    "- Replace infinities with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Cleaning on All Datasets\n",
    "\n",
    "Process all three datasets:\n",
    "- **Madrid Q1 2025**: Training data\n",
    "- **Madrid Q2 2025**: Temporal validity\n",
    "- **Valencia Q1 2025**: External validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CLEANING: madrid_25q1\n",
      "============================================================\n",
      "\n",
      "Loaded: 25288 rows, 79 columns\n",
      "After price filter: 19179 rows\n",
      "After excluding hotels/hostels: 18688 rows\n",
      "\n",
      "Final shape: (18169, 71)\n",
      "Saved to: C:\\Users\\borik\\Desktop\\Data-Analysis-3\\assignment1\\data\\clean/airbnb_madrid_25q1_clean.csv\n",
      "Price: mean=121, median=98\n",
      "\n",
      "============================================================\n",
      "CLEANING: madrid_25q2\n",
      "============================================================\n",
      "\n",
      "Loaded: 26004 rows, 79 columns\n",
      "After price filter: 19969 rows\n",
      "After excluding hotels/hostels: 19481 rows\n",
      "\n",
      "Final shape: (19035, 71)\n",
      "Saved to: C:\\Users\\borik\\Desktop\\Data-Analysis-3\\assignment1\\data\\clean/airbnb_madrid_25q2_clean.csv\n",
      "Price: mean=124, median=101\n",
      "\n",
      "============================================================\n",
      "CLEANING: valencia_25q1\n",
      "============================================================\n",
      "\n",
      "Loaded: 8847 rows, 79 columns\n",
      "After price filter: 8081 rows\n",
      "After excluding hotels/hostels: 7945 rows\n",
      "\n",
      "Final shape: (7606, 71)\n",
      "Saved to: C:\\Users\\borik\\Desktop\\Data-Analysis-3\\assignment1\\data\\clean/airbnb_valencia_25q1_clean.csv\n",
      "Price: mean=131, median=114\n",
      "\n",
      "============================================================\n",
      "ALL DATASETS CLEANED SUCCESSFULLY\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Clean all three datasets\n",
    "datasets = [\"madrid_25q1\", \"madrid_25q2\", \"valencia_25q1\"]\n",
    "\n",
    "cleaned_data = {}\n",
    "for dataset in datasets:\n",
    "    cleaned_data[dataset] = clean_dataset(dataset)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALL DATASETS CLEANED SUCCESSFULLY\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Comparison:\n",
      "--------------------------------------------------\n",
      "madrid_25q1: 18,169 obs, 71 vars, mean price=€121\n",
      "madrid_25q2: 19,035 obs, 71 vars, mean price=€124\n",
      "valencia_25q1: 7,606 obs, 71 vars, mean price=€131\n"
     ]
    }
   ],
   "source": [
    "# Summary comparison\n",
    "print(\"\\nDataset Comparison:\")\n",
    "print(\"-\" * 50)\n",
    "for name, df in cleaned_data.items():\n",
    "    print(f\"{name}: {df.shape[0]:,} obs, {df.shape[1]} vars, \"\n",
    "          f\"mean price=€{df['price'].mean():.0f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:daenv]",
   "language": "python",
   "name": "conda-env-daenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
